# Python package
# Create and test a Python package on multiple Python versions.
# Add steps that analyze code, save the dist with the build record, publish to a PyPI-compatible index, and more:
# https://docs.microsoft.com/azure/devops/pipelines/languages/python

trigger:
- main

pool: 
  vmImage: ubuntu-latest

variables:
  tag: "$(Build.BuildId)"
  image: "manmohanb/pygoat"

stages:
 
- stage: build
  jobs:
    - job: build_and_push_app
      displayName: Build and Push App
      steps:

      - task: UsePythonVersion@0
        inputs:
          versionSpec: '3.8'
          addToPath: true
          architecture: 'x64'
        displayName: 'Setup Python'

      - script: |
          pip install -r requirements.txt
        displayName: 'Install Dependencies'
      
      - task: Docker@2
        inputs:
          containerRegistry: 'dockerhub'
          repository: '$(image)'
          command: 'buildAndPush'
          Dockerfile: '**/Dockerfile'
        displayName: 'Build and Push Docker image'
          
- stage: test
  dependsOn: build
  jobs:
    
    - job: run_sca_analysis
      displayName: Run SCA Analysis
      steps:
      
      - task: CmdLine@2
        inputs:
          script: |
            pip install safety
            safety check -r requirements.txt --continue-on-error --output json > $(Pipeline.Workspace)/dependency-check-report.json
        displayName: 'Safety Dependency Check'

      - task: PublishPipelineArtifact@1
        inputs:
          targetPath: '$(Pipeline.Workspace)/dependency-check-report.json'
          artifact: 'dependency-check-report'
          publishLocation: 'pipeline'

      - task: CmdLine@2
        inputs:
           script: |
             # Install the Docker Scout CLI
             curl -sSfL https://raw.githubusercontent.com/docker/scout-cli/main/install.sh | sh -s --
             # Login to Docker Hub required for Docker Scout CLI
             docker login -u $(DOCKER_HUB_USER) -p $(DOCKER_HUB_PAT)
             # Get a CVE report for the built image and fail the pipeline when critical or high CVEs are detected
             docker scout cves $(image):$(tag) --only-severity critical,high --format sarif --output $(Pipeline.Workspace)/image-scan-report.json
        displayName: Image Scanning

      - task: PublishPipelineArtifact@1
        inputs:
          targetPath: '$(Pipeline.Workspace)/image-scan-report.json'
          artifact: 'image-scan-report'
          publishLocation: 'pipeline'
        condition: succeededOrFailed()
        displayName: 'Publish Image Scan Report'

    - job: run_unit_tests
      displayName: Run Unit Tests
      steps:
      - task: UsePythonVersion@0
        inputs:
          versionSpec: '3.8'
          addToPath: true
          architecture: 'x64'
        displayName: 'Setup Python'

      - script: |
          pip install -r requirements.txt
        displayName: 'Install Dependencies'

      - script: |
          python -m pip install pytest-azurepipelines pytest-cov
          python -m pytest introduction/tests/unit/ --junitxml=$(Pipeline.Workspace)/TEST-output.xml --cov=. --cov-report=xml
        displayName: 'UnitTests with PyTest'
      - task: PublishPipelineArtifact@1
        inputs:
          targetPath: '$(Pipeline.Workspace)/TEST-output.xml'
          artifact: 'unit-test-results'
          publishLocation: 'pipeline'
        condition: succeededOrFailed()
        displayName: 'Publish UnitTest Report'

    - job: run_sast_analysis
      displayName: Run SAST Analysis
      steps:
      - task: CmdLine@2
        inputs:
          script: |
            pip3 install --upgrade pip
            pip3 install --upgrade setuptools
            pip3 install bandit
            bandit -ll -ii -r ./introduction -f json -o $(Pipeline.Workspace)/sast-report.json --exit-zero
        displayName: 'Bandit Scan'
      
      - task: PublishPipelineArtifact@1
        inputs:
          targetPath: '$(Pipeline.Workspace)/sast-report.json'
          artifact: 'bandit-sast-report'
          publishLocation: 'pipeline'
        condition: succeededOrFailed()
        displayName: 'Publish SAST Scan Report'
- stage: dast
  dependsOn: deploy_test
  jobs:
  - job: run_integration_tests
    displayName: Run Integration Tests
    steps:
# for containerised apps you can run the DAST and Integration tests against a container running inside the pipeline itself (instead of deploying to an external url)    
    # - task: CmdLine@2
    #   inputs:
    #     script: 'docker run -d -p 8000:8000 $(image):$(tag)'
    #   displayName: 'Run Container Inside Pipeline'

    - script: |
        python -m pip install -r requirements.txt
        python -m pip install pytest-cov
        python -m pytest introduction/tests/integration/ --junitxml=$(Pipeline.Workspace)/selenium-test-output.xml --cov=. --cov-report=xml
      condition: succeededOrFailed()
      displayName: 'Integration Tests with Selenium'
    - task: PublishPipelineArtifact@1
      inputs:
        targetPath: '$(Pipeline.Workspace)/selenium-test-output.xml'
        artifact: 'selenium-test-results'
        publishLocation: 'pipeline'
      condition: succeededOrFailed()
      displayName: 'Publish Selenium Report'

  - job: run_dast_scan
    displayName: Run DAST Scan
    steps:    
    - task: owaspzap@1
      inputs:
        scantype: 'targetedScan'
        url: 'http://pygoat.example.com'
      displayName: 'OWASP ZAP Scan'
    
    - task: CopyFiles@2
      condition: succeededOrFailed()
      inputs:
        SourceFolder: 'owaspzap/'
        TargetFolder: '$(Pipeline.Workspace)'
    
    - task: PublishPipelineArtifact@1
      condition: succeededOrFailed()
      inputs:
        targetPath: '$(Pipeline.Workspace)/report.json'
        artifact: 'owasp_zap_report'
        publishLocation: 'pipeline'
      displayName: 'Publish ZAP Report'
